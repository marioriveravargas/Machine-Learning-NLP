{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U pip setuptools wheel\n",
    "#!pip install -U spacy\n",
    "#!python -m spacy download en_core_web_sm\n",
    "#!pip install astropy\n",
    "#!pip install python-math\n",
    "#!pip install missingno\n",
    "#!pip install regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import astropy as ast\n",
    "import python_math as math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from gensim.corpora.textcorpus import strip_multiple_whitespaces\n",
    "\n",
    "# For word lemmitization\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_training = pd.read_csv(\"/Users/marioriveravargas/Downloads/Machine-Learning-NLP-main/Competencia/datos/dataTraining.csv\", sep=\",\" , index_col=0)\n",
    "movies_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_training.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing - Label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_training['genres_process']=movies_training['genres'].apply(lambda x: eval(x))\n",
    "movies_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel = MultiLabelBinarizer()\n",
    "y = multilabel.fit_transform(movies_training['genres_process'])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pd.DataFrame(y, columns= multilabel.classes_)\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = movies_training[['title', 'plot']].reset_index(drop=True)\n",
    "data_train = pd.concat([data, tags], axis=1)\n",
    "data_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de datos - Null Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(data_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se verifica que no hay valores perdidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversión de columnas categóricas\n",
    "\n",
    "Convertimos todo el conjunto de características de género(salidas) en tipos categóricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = data_train.columns.drop(['title', 'plot'])\n",
    "for col in tags:\n",
    "    data_train[col] = data_train[col].astype('category')\n",
    "\n",
    "data_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_genre = pd.DataFrame(tags[data_train.columns.drop(['title', 'plot'])].sum()).reset_index()\n",
    "sum_genre.columns = ['Genre', 'Total']\n",
    "sum_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(12, 10))\n",
    "sns.barplot(data=sum_genre, x='Genre', y='Total', axes=ax)\n",
    "ax.set(ylabel='Número de películas')\n",
    "plt.title('Número de películas por género', loc='center', fontdict={'fontsize':16})\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observaciones\n",
    "\n",
    "* Las películas de género más bajas son Animation, Film-noir, History, Short and News.\n",
    "* Las películas de género más altas son Drama (3965 películas), seguidas de Comedia (3046 películas) y Thriller (2024 películas )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Número de géneros por película"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_movie = data_train[category].sum(axis=1)\n",
    "df_genres_per_movie = pd.DataFrame({'title': data_train.title, 'num_genres':sum_movie}).groupby('num_genres').count()\n",
    "f, ax = plt.subplots(1, 1, figsize=(12, 10))\n",
    "sns.barplot(data=df_genres_per_movie, x=df_genres_per_movie.index, y='title', axes=ax)\n",
    "ax.set(xlabel='Número de géneros para una película', ylabel='Número de películas')\n",
    "plt.title('Número de géneros por película', loc='center', fontdict={'fontsize':16})\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('En promedio, las películas se clasifican en {0:.2f} géneros'.format(sum_movie.mean()))\n",
    "print('Número de películas con mas de 4 géneros. = {0}'.format(len(sum_movie[sum_movie==4])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "fig = plt.figure(figsize=(18, 70))\n",
    "num_cols = 2\n",
    "num_rows = math.ceil(len(category)/num_cols)\n",
    "for idx, col in enumerate(category):\n",
    "    wordcloud = WordCloud(max_font_size=50).generate(' '.join(data_train[data_train[col]==1]['plot']))\n",
    "    ax = fig.add_subplot(num_rows, num_cols, idx+1)\n",
    "    ax.imshow(wordcloud)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set(title='Movie Genre: {0}'.format(col))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de correlación de género\n",
    "Ahora veamos qué géneros están mayormente correlacionados. En otras palabras, si una película es, por ejemplo, Acción, ¿cuáles son los otros géneros en los que puede caer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap relative to all numeric columns\n",
    "corr_matrix = (data_train[category].astype('int')).corr()\n",
    "mask = np.array(corr_matrix)\n",
    "mask[np.tril_indices_from(mask)] = False\n",
    "corr_matrix = (100*corr_matrix//1)/10\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, cbar=True, vmax=7, vmin=-7, cmap='RdYlGn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las siguientes categorías de género muestran una fuerte correlación positiva entre sí\n",
    "* Acción, Aventura y Ciencia Ficción\n",
    "* Animación, Fantasía y Familia\n",
    "* Crimen, Thriller, Misterio y Drama\n",
    "* Biografía, Documental e Historia\n",
    "* drama y romanticismo\n",
    "* Programa de juegos y telerrealidad\n",
    "* Terror, Thriller y Fantasia\n",
    "* Programa de entrevistas y noticias\n",
    "* Guerra e Historia\n",
    "\n",
    "Las siguientes categorías de género muestran una fuerte correlación negativa entre sí\n",
    "* Animación y Teatro\n",
    "* Comedia con Documental y Reality-TV\n",
    "* Documental con Comedia, Drama y Romance\n",
    "* Drama con Animación, Reality TV y Comedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de los datos\n",
    "\n",
    "Aquí limpiamos nuestros datos (trama de la película) usando las siguientes técnicas de preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U pip setuptools wheel\n",
    "#!pip install -U 'spacy[apple]'\n",
    "#!python -m spacy download en_core_web\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install strings\n",
    "#nlp = spacy.load('en_core_web_trf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Function to process the the text text and tranform it into format usable by Machine learning models\n",
    "    \"\"\"\n",
    "    # remove line breaks\n",
    "    text = text.replace('\\n', ' ')\n",
    "    # to convert all the characters of the text into lower case alphabets\n",
    "    text = text.lower()\n",
    "    #remove numbers\n",
    "    text = re.sub(r'[0-9]+', '', text) #remove numbers\n",
    "    # Remove urls from the texts\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    #remove emails\n",
    "    text = re.sub('\\S*@\\S*\\s?', '', text)\n",
    "    # Remove user related references from the texts:: '@' and '#' \n",
    "    text = re.sub(r'\\@\\w+|\\#','', text)\n",
    "    #remove spaces\n",
    "    text = strip_multiple_whitespaces(text) \n",
    "    # Remove punctuations from the texts\n",
    "    #text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Lemmatizerr\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemma_words = [lemmatizer.lemmatize(w, pos='v') for w in text.split()]\n",
    "\n",
    "    joined_text = \" \".join(lemma_words)\n",
    "    return joined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['plot_clean'] = data_train['plot'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data_train, random_state=42, test_size=0.15, shuffle=True)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train['plot_clean']\n",
    "test_text = test['plot_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2')\n",
    "vectorizer.fit(train_text)\n",
    "vectorizer.fit(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorizer.transform(train_text)\n",
    "y_train = train.drop(labels = ['title','plot','plot_clean'], axis=1)\n",
    "\n",
    "x_test = vectorizer.transform(test_text)\n",
    "y_test = test.drop(labels = ['title','plot','plot_clean'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Label Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'category' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'category' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Using pipeline for applying logistic regression and one vs rest classifier\n",
    "accuracy=0\n",
    "LogReg_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),\n",
    "            ])\n",
    "\n",
    "for cat in category.tolist():\n",
    "    printmd('**Processing {} Multilabel Clasification...**'.format(cat))\n",
    "    \n",
    "    # Training logistic regression model on train data\n",
    "    LogReg_pipeline.fit(x_train, train[cat])\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    prediction = LogReg_pipeline.predict(x_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[cat], prediction)))\n",
    "    print('Test Recall is {}'.format(recall_score(test[cat], prediction)))\n",
    "    print('Test f1_score is {}'.format(f1_score(test[cat], prediction)))\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Using pipeline for applying logistic regression and one vs rest classifier\n",
    "LogReg_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(SGDClassifier(), n_jobs=-1)),\n",
    "            ])\n",
    "\n",
    "for cat in category.tolist():\n",
    "    printmd('**Processing {} Multilabel Clasification...**'.format(cat))\n",
    "    \n",
    "    # Training logistic regression model on train data\n",
    "    LogReg_pipeline.fit(x_train, train[cat])\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    prediction = LogReg_pipeline.predict(x_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[cat], prediction)))\n",
    "    print('Test Recall is {}'.format(recall_score(test[cat], prediction)))\n",
    "    print('Test f1_score is {}'.format(f1_score(test[cat], prediction)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Using pipeline for applying logistic regression and one vs rest classifier\n",
    "LogReg_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None), n_jobs=-1)),\n",
    "            ])\n",
    "\n",
    "for cat in category.tolist():\n",
    "    printmd('**Processing {} Multilabel Clasification...**'.format(cat))\n",
    "    \n",
    "    # Training logistic regression model on train data\n",
    "    LogReg_pipeline.fit(x_train, train[cat])\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    prediction = LogReg_pipeline.predict(x_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[cat], prediction)))\n",
    "    print('Test Recall is {}'.format(recall_score(test[cat], prediction)))\n",
    "    print('Test f1_score is {}'.format(f1_score(test[cat], prediction)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b_/9gjbt5hx7b71v8dgpt18f8340000gn/T/ipykernel_78540/3244788460.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'plot_clean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'plot_clean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "maxlen = 200\n",
    "tokenizer = Tokenizer(num_words=5000, lower=True)\n",
    "tokenizer.fit_on_texts(data_train['plot_clean'])\n",
    "sequences = tokenizer.texts_to_sequences(data_train['plot_clean'])\n",
    "x = pad_sequences(sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_n = data_train[['plot','plot_clean', 'Action', 'Adventure', 'Animation', 'Biography',\n",
    "       'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy',\n",
    "       'Film-Noir', 'History', 'Horror', 'Music', 'Musical', 'Mystery', 'News',\n",
    "       'Romance', 'Sci-Fi', 'Short', 'Sport', 'Thriller', 'War', 'Western']]\n",
    "data_n.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = y_train.shape[1] \n",
    "Y_train = to_categorical(y_train, num_classes)\n",
    "Y_test = to_categorical(y_train, num_classes)\n",
    "\n",
    "max_words = len(tokenizer.word_index) + 1\n",
    "print(f\"Numero de clases:{num_classes}\")\n",
    "print(f\"Max Words:{max_words}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelado\n",
    "# ==============================================================================\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos\n",
    "# ==============================================================================\n",
    "modelo_1 = MLPClassifier(\n",
    "                hidden_layer_sizes=(5),\n",
    "                learning_rate_init=0.01,\n",
    "                solver = 'lbfgs',\n",
    "                max_iter = 1000,\n",
    "                random_state = 123\n",
    "            )\n",
    "\n",
    "modelo_2 = MLPClassifier(\n",
    "                hidden_layer_sizes=(10),\n",
    "                learning_rate_init=0.01,\n",
    "                solver = 'lbfgs',\n",
    "                max_iter = 1000,\n",
    "                random_state = 123\n",
    "            )\n",
    "\n",
    "modelo_3 = MLPClassifier(\n",
    "                hidden_layer_sizes=(20, 20),\n",
    "                learning_rate_init=0.01,\n",
    "                solver = 'lbfgs',\n",
    "                max_iter = 5000,\n",
    "                random_state = 123\n",
    "            )\n",
    "\n",
    "modelo_4 = MLPClassifier(\n",
    "                hidden_layer_sizes=(50, 50, 50),\n",
    "                learning_rate_init=0.01,\n",
    "                solver = 'lbfgs',\n",
    "                max_iter = 5000,\n",
    "                random_state = 123\n",
    "            )\n",
    "\n",
    "modelo_1.fit(X=X, y=y)\n",
    "modelo_2.fit(X=X, y=y)\n",
    "modelo_3.fit(X=X, y=y)\n",
    "modelo_4.fit(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de predicciones\n",
    "# ==============================================================================\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12,8))\n",
    "axs = axs.flatten()\n",
    "grid_x1 = np.linspace(start=min(X[:, 0]), stop=max(X[:, 0]), num=100)\n",
    "grid_x2 = np.linspace(start=min(X[:, 1]), stop=max(X[:, 1]), num=100)\n",
    "xx, yy = np.meshgrid(grid_x1, grid_x2)\n",
    "X_grid = np.column_stack([xx.flatten(), yy.flatten()])\n",
    "\n",
    "for i, modelo in enumerate([modelo_1, modelo_2, modelo_3, modelo_4]):\n",
    "    \n",
    "    predicciones = modelo.predict(X_grid)\n",
    "    \n",
    "    for j in np.unique(predicciones):\n",
    "        axs[i].scatter(\n",
    "            x = X_grid[predicciones == j, 0],\n",
    "            y = X_grid[predicciones == j, 1], \n",
    "            c = plt.rcParams['axes.prop_cycle'].by_key()['color'][j],\n",
    "            #marker = 'o',\n",
    "            alpha = 0.3,\n",
    "            label= f\"Grupo {j}\"\n",
    "        )\n",
    "\n",
    "    for j in np.unique(y):\n",
    "        axs[i].scatter(\n",
    "            x = X[y == j, 0],\n",
    "            y = X[y == j, 1], \n",
    "            c = plt.rcParams['axes.prop_cycle'].by_key()['color'][j],\n",
    "            marker    = 'o',\n",
    "            edgecolor = 'black'\n",
    "        )\n",
    "        \n",
    "    axs[i].set_title(f\"Capas ocultas: {modelo.hidden_layer_sizes}\")\n",
    "    axs[i].axis('off')\n",
    "axs[0].legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de neuronas\n",
    "# ==============================================================================\n",
    "param_grid = {'hidden_layer_sizes':[1, 5, 10, 15, 25, 50]}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "        estimator = MLPClassifier(\n",
    "                        learning_rate_init=0.01,\n",
    "                        solver = 'lbfgs',\n",
    "                        alpha  = 0,\n",
    "                        max_iter = 5000,\n",
    "                        random_state = 123\n",
    "                    ),\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'accuracy',\n",
    "        cv         = 5,\n",
    "        refit      = True,\n",
    "        return_train_score = True\n",
    "      )\n",
    "\n",
    "_ = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "scores = pd.DataFrame(grid.cv_results_)\n",
    "scores.plot(x='param_hidden_layer_sizes', y='mean_train_score', yerr='std_train_score', ax=ax)\n",
    "scores.plot(x='param_hidden_layer_sizes', y='mean_test_score', yerr='std_test_score', ax=ax)\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.set_xlabel('número de neuronas')\n",
    "ax.set_title('Error de validacion cruzada');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "# ==============================================================================\n",
    "param_grid = {'learning_rate_init':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "        estimator = MLPClassifier(\n",
    "                        hidden_layer_sizes=(10),\n",
    "                        solver = 'adam',\n",
    "                        alpha  = 0,\n",
    "                        max_iter = 5000,\n",
    "                        random_state = 123\n",
    "                    ),\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'accuracy',\n",
    "        cv         = 5,\n",
    "        refit      = True,\n",
    "        return_train_score = True\n",
    "      )\n",
    "\n",
    "_ = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "scores = pd.DataFrame(grid.cv_results_)\n",
    "scores.plot(x='param_learning_rate_init', y='mean_train_score', yerr='std_train_score', ax=ax)\n",
    "scores.plot(x='param_learning_rate_init', y='mean_test_score', yerr='std_test_score', ax=ax)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('log(learning rate)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Espacio de búsqueda de cada hiperparámetro\n",
    "# ==============================================================================\n",
    "param_distributions = {\n",
    "    'hidden_layer_sizes': [(10), (10, 10), (20, 20)],\n",
    "    'alpha': np.logspace(-3, 3, 7),\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "}\n",
    "\n",
    "# Búsqueda por validación cruzada\n",
    "# ==============================================================================\n",
    "grid = RandomizedSearchCV(\n",
    "        estimator  = MLPClassifier(solver = 'lbfgs', max_iter= 2000),\n",
    "        param_distributions = param_distributions,\n",
    "        n_iter     = 50, # Número máximo de combinaciones probadas\n",
    "        scoring    = 'accuracy',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = 3, \n",
    "        verbose    = 0,\n",
    "        random_state = 123,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "grid.fit(X = X, y = y)\n",
    "\n",
    "# Resultados del grid\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(grid.cv_results_)\n",
    "resultados.filter(regex = '(param.*|mean_t|std_t)')\\\n",
    "    .drop(columns = 'params')\\\n",
    "    .sort_values('mean_test_score', ascending = False)\\\n",
    "    .head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = grid.best_estimator_\n",
    "modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_x1 = np.linspace(start=min(X[:, 0]), stop=max(X[:, 0]), num=100)\n",
    "grid_x2 = np.linspace(start=min(X[:, 1]), stop=max(X[:, 1]), num=100)\n",
    "xx, yy = np.meshgrid(grid_x1, grid_x2)\n",
    "\n",
    "X_grid = np.column_stack([xx.flatten(), yy.flatten()])\n",
    "predicciones = modelo.predict(X_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "for i in np.unique(predicciones):\n",
    "    ax.scatter(\n",
    "        x = X_grid[predicciones == i, 0],\n",
    "        y = X_grid[predicciones == i, 1], \n",
    "        c = plt.rcParams['axes.prop_cycle'].by_key()['color'][i],\n",
    "        #marker = 'o',\n",
    "        alpha = 0.3,\n",
    "        label= f\"Grupo {i}\"\n",
    "    )\n",
    "\n",
    "for i in np.unique(y):\n",
    "    ax.scatter(\n",
    "        x = X[y == i, 0],\n",
    "        y = X[y == i, 1], \n",
    "        c = plt.rcParams['axes.prop_cycle'].by_key()['color'][i],\n",
    "        marker    = 'o',\n",
    "        edgecolor = 'black'\n",
    "    )\n",
    "    \n",
    "\n",
    "ax.set_title('Regiones de clasificación')\n",
    "ax.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=30,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.3,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = model\n",
    "metrics = cnn_model.evaluate(X_test, y_test)\n",
    "# evaluate model\n",
    "training_report_Keras = 'Training Report CNN: ' + '\\n'\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "training_report_Keras += f'\\nTest accuracy:\\t\\t{test_accuracy:.4f}\\t- Test loss:\\t\\t{test_loss:.4f}\\n'\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "y_true = np.array([np.argmax(y) for y in y_test])\n",
    "y_pred = np.array([np.argmax(y) for y in preds])\n",
    "y_prob = np.array([np.amax(y) for y in preds])\n",
    "\n",
    "\n",
    "training_report_Keras += classification_report(y_true, y_pred, digits=4)\n",
    "\n",
    "print(training_report_Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "\n",
    "\n",
    "glove_file = open('/Users/natalia/Downloads/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary[word] = vector_dimensions\n",
    "glove_file.close()\n",
    "\n",
    "embedding_matrix = zeros((max_words, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.models import Model\n",
    "\n",
    "deep_inputs = Input(shape=(maxlen,))\n",
    "embedding_layer = Embedding(max_words, 100, weights=[embedding_matrix], trainable=False)(deep_inputs)\n",
    "LSTM_Layer_1 = LSTM(128)(embedding_layer)\n",
    "dense_layer_1 = Dense(num_classes, activation='sigmoid')(LSTM_Layer_1)\n",
    "model = Model(inputs=deep_inputs, outputs=dense_layer_1)\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(),\n",
    "    ModelCheckpoint(filepath='model-conv1d.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.AUC()])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=32, \n",
    "                    epochs=30, \n",
    "                    validation_split=0.3,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = model\n",
    "metrics = lstm_model.evaluate(X_test, y_test)\n",
    "# evaluate model\n",
    "training_report_Keras = 'Training Report CNN: ' + '\\n'\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "training_report_Keras += f'\\nTest accuracy:\\t\\t{test_accuracy:.4f}\\t- Test loss:\\t\\t{test_loss:.4f}\\n'\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "y_true = np.array([np.argmax(y) for y in y_test])\n",
    "y_pred = np.array([np.argmax(y) for y in preds])\n",
    "y_prob = np.array([np.amax(y) for y in preds])\n",
    "\n",
    "\n",
    "training_report_Keras += classification_report(y_true, y_pred, digits=4)\n",
    "\n",
    "print(training_report_Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9415b887b4ee2af25ed95d17880dc13325d5a8f90e970abe1c90a0542ab3c878"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
